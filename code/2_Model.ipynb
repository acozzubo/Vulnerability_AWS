{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACS 30123 Final Project: Vulnerability Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive model and Vulnerability Line estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook deploys a Machine Learning pipeline to find the best  model to predict households that will fall into poverty in the next year. For that, it uses the panel dataset 2007-2019.\n",
    "#### After gridsearching, contrasting rival models and obtaining the best model from different algorithms; it predicts a vulnerability risk out of sample using the cross section database 2007-2019.\n",
    "#### With this latter database, the vulnerability is computed as the average expenditures deflacted by year and space (PEN, Lima prices 2018) for households in a given threshold. \n",
    "#### As the literature suggest, the threshold is chosen based on the results from the transition matrix. Hence, the threshold is set at 9% with a caliper of Â±1%. That is, the vulnerability line will be computed as the average expenditure of the households with a risk of falling into poverty from 8-10%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-2J7MEMQT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11a71822408>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "import pandas as pd\n",
    "import math\n",
    "# Find Spark so that we can access session within our notebook\n",
    "import findspark\n",
    "findspark.init()\n",
    "# Start SparkSession on all available cores\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "#check\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_data = spark.read.csv(r'D:\\Drive\\UChicago\\courses\\Fall 2020\\Large Scale Computing - Clindaniel\\project\\201129_bianual_apilado_07_19.csv',\n",
    "                      header=True, inferSchema=True)\n",
    "cs_data = spark.read.csv(r'D:\\Drive\\UChicago\\courses\\Fall 2020\\Large Scale Computing - Clindaniel\\project\\201129_corte_apilado_07_19.csv',\n",
    "                      header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missings \n",
    "#panel_data = panel_data.dropna()\n",
    "#cs_data = cs_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 318\n",
      "Total Rows: 70067\n",
      "root\n",
      " |-- panel: string (nullable = true)\n",
      " |-- conglome_t0: integer (nullable = true)\n",
      " |-- vivienda_t0: integer (nullable = true)\n",
      " |-- hogar_t0: integer (nullable = true)\n",
      " |-- aband_jefe: integer (nullable = true)\n",
      " |-- area: integer (nullable = true)\n",
      " |-- vtenencia: string (nullable = true)\n",
      " |-- vagua: integer (nullable = true)\n",
      " |-- vsshh: integer (nullable = true)\n",
      " |-- valum: integer (nullable = true)\n",
      " |-- vacceso: integer (nullable = true)\n",
      " |-- vpared: integer (nullable = true)\n",
      " |-- vpiso: integer (nullable = true)\n",
      " |-- hinternet: integer (nullable = true)\n",
      " |-- htelef: integer (nullable = true)\n",
      " |-- gedad_1: integer (nullable = true)\n",
      " |-- gedad_2: integer (nullable = true)\n",
      " |-- gedad_3: integer (nullable = true)\n",
      " |-- genero: integer (nullable = true)\n",
      " |-- hog_nucl: integer (nullable = true)\n",
      " |-- hog_monopa: integer (nullable = true)\n",
      " |-- monop_homb: integer (nullable = true)\n",
      " |-- monop_muj: integer (nullable = true)\n",
      " |-- ratiodep: double (nullable = true)\n",
      " |-- edad_mean: double (nullable = true)\n",
      " |-- hombres: integer (nullable = true)\n",
      " |-- conyuge: integer (nullable = true)\n",
      " |-- hpob65: integer (nullable = true)\n",
      " |-- hunip65: integer (nullable = true)\n",
      " |-- hriesgo: integer (nullable = true)\n",
      " |-- h65menor17: integer (nullable = true)\n",
      " |-- hacinamien: integer (nullable = true)\n",
      " |-- gas_svstot: integer (nullable = true)\n",
      " |-- gas_svsal: integer (nullable = true)\n",
      " |-- choque_s5: integer (nullable = true)\n",
      " |-- ubigeo_t0: integer (nullable = true)\n",
      " |-- dominio_t0: string (nullable = true)\n",
      " |-- mis_gob: integer (nullable = true)\n",
      " |-- ing_inest_1: integer (nullable = true)\n",
      " |-- ing_inest_2: integer (nullable = true)\n",
      " |-- ing_inest_3: integer (nullable = true)\n",
      " |-- choq_emple: integer (nullable = true)\n",
      " |-- choq_quiebr: integer (nullable = true)\n",
      " |-- choq_robo: integer (nullable = true)\n",
      " |-- choq_desast: integer (nullable = true)\n",
      " |-- choq_otros: integer (nullable = true)\n",
      " |-- num_choq: integer (nullable = true)\n",
      " |-- choq_combi: integer (nullable = true)\n",
      " |-- estrategia: string (nullable = true)\n",
      " |-- si_soldism_ibp: integer (nullable = true)\n",
      " |-- no_soldism_ibp: integer (nullable = true)\n",
      " |-- piso_alt_1: integer (nullable = true)\n",
      " |-- piso_alt_2: integer (nullable = true)\n",
      " |-- piso_alt_3: integer (nullable = true)\n",
      " |-- piso_alt_4: integer (nullable = true)\n",
      " |-- piso_alt_5: integer (nullable = true)\n",
      " |-- piso_alt_6: integer (nullable = true)\n",
      " |-- piso_alt_7: integer (nullable = true)\n",
      " |-- piso_alt_8: integer (nullable = true)\n",
      " |-- hauto: integer (nullable = true)\n",
      " |-- hrefri: integer (nullable = true)\n",
      " |-- htv: integer (nullable = true)\n",
      " |-- hdvd: integer (nullable = true)\n",
      " |-- heqsonido: integer (nullable = true)\n",
      " |-- hradio: integer (nullable = true)\n",
      " |-- hcocina: integer (nullable = true)\n",
      " |-- hactivos: integer (nullable = true)\n",
      " |-- no_asocia: integer (nullable = true)\n",
      " |-- indigena: integer (nullable = true)\n",
      " |-- educa: string (nullable = true)\n",
      " |-- seg_sis: integer (nullable = true)\n",
      " |-- seg_essal: integer (nullable = true)\n",
      " |-- seg_otro: integer (nullable = true)\n",
      " |-- seg_nocuen: integer (nullable = true)\n",
      " |-- sector: string (nullable = true)\n",
      " |-- yyeduc: integer (nullable = true)\n",
      " |-- yyeduc2: integer (nullable = true)\n",
      " |-- ratio_educ: double (nullable = true)\n",
      " |-- num_hosp: integer (nullable = true)\n",
      " |-- num_accid: integer (nullable = true)\n",
      " |-- hindemp5: integer (nullable = true)\n",
      " |-- htrabemp10: integer (nullable = true)\n",
      " |-- hocu1417: integer (nullable = true)\n",
      " |-- choque_s1: integer (nullable = true)\n",
      " |-- choque_s2: integer (nullable = true)\n",
      " |-- choque_s3: integer (nullable = true)\n",
      " |-- choque_s4: integer (nullable = true)\n",
      " |-- estratosocio: string (nullable = true)\n",
      " |-- mieperho: integer (nullable = true)\n",
      " |-- inghog1d_t0: double (nullable = true)\n",
      " |-- gashog2d_t0: double (nullable = true)\n",
      " |-- linea_t0: double (nullable = true)\n",
      " |-- mieperho_t1: integer (nullable = true)\n",
      " |-- inghog1d_t1: double (nullable = true)\n",
      " |-- gashog2d_t1: double (nullable = true)\n",
      " |-- linea_t1: double (nullable = true)\n",
      " |-- i00_t0: double (nullable = true)\n",
      " |-- i00_t1: double (nullable = true)\n",
      " |-- ld_t0: double (nullable = true)\n",
      " |-- ld_t1: double (nullable = true)\n",
      " |-- facpanel17: double (nullable = true)\n",
      " |-- factorhogar_bi: double (nullable = true)\n",
      " |-- dep_1: integer (nullable = true)\n",
      " |-- dep_2: integer (nullable = true)\n",
      " |-- dep_3: integer (nullable = true)\n",
      " |-- dep_4: integer (nullable = true)\n",
      " |-- dep_5: integer (nullable = true)\n",
      " |-- dep_6: integer (nullable = true)\n",
      " |-- dep_7: integer (nullable = true)\n",
      " |-- dep_8: integer (nullable = true)\n",
      " |-- dep_9: integer (nullable = true)\n",
      " |-- dep_10: integer (nullable = true)\n",
      " |-- dep_11: integer (nullable = true)\n",
      " |-- dep_12: integer (nullable = true)\n",
      " |-- dep_13: integer (nullable = true)\n",
      " |-- dep_14: integer (nullable = true)\n",
      " |-- dep_16: integer (nullable = true)\n",
      " |-- dep_17: integer (nullable = true)\n",
      " |-- dep_18: integer (nullable = true)\n",
      " |-- dep_19: integer (nullable = true)\n",
      " |-- dep_20: integer (nullable = true)\n",
      " |-- dep_21: integer (nullable = true)\n",
      " |-- dep_22: integer (nullable = true)\n",
      " |-- dep_23: integer (nullable = true)\n",
      " |-- dep_24: integer (nullable = true)\n",
      " |-- dep_25: integer (nullable = true)\n",
      " |-- dep_26: integer (nullable = true)\n",
      " |-- dep_27: integer (nullable = true)\n",
      " |-- end_lacexc: double (nullable = true)\n",
      " |-- end_anemia: double (nullable = true)\n",
      " |-- end_ira: double (nullable = true)\n",
      " |-- end_eda: double (nullable = true)\n",
      " |-- end_bajpeso: double (nullable = true)\n",
      " |-- end_cred: double (nullable = true)\n",
      " |-- end_suphierro: double (nullable = true)\n",
      " |-- end_aguatrat: double (nullable = true)\n",
      " |-- end_saneabas: double (nullable = true)\n",
      " |-- end_gestsuphie: double (nullable = true)\n",
      " |-- end_usometpf: double (nullable = true)\n",
      " |-- end_partinst: double (nullable = true)\n",
      " |-- end_cesarea: double (nullable = true)\n",
      " |-- end_prematuro: double (nullable = true)\n",
      " |-- end_primercpn: double (nullable = true)\n",
      " |-- end_cpn6: double (nullable = true)\n",
      " |-- mun_dis: integer (nullable = true)\n",
      " |-- v10: integer (nullable = true)\n",
      " |-- v10_01: integer (nullable = true)\n",
      " |-- v10_02: integer (nullable = true)\n",
      " |-- v10_03: integer (nullable = true)\n",
      " |-- v10_04: integer (nullable = true)\n",
      " |-- v10_05: integer (nullable = true)\n",
      " |-- v10_06: integer (nullable = true)\n",
      " |-- v10_07: integer (nullable = true)\n",
      " |-- v11: integer (nullable = true)\n",
      " |-- v11_1: integer (nullable = true)\n",
      " |-- v11_2: integer (nullable = true)\n",
      " |-- v11_3: integer (nullable = true)\n",
      " |-- v11_4: integer (nullable = true)\n",
      " |-- v11_5: integer (nullable = true)\n",
      " |-- v11_6: integer (nullable = true)\n",
      " |-- v11_7: integer (nullable = true)\n",
      " |-- v11_8: integer (nullable = true)\n",
      " |-- v11_9: integer (nullable = true)\n",
      " |-- v11_10: integer (nullable = true)\n",
      " |-- v12: integer (nullable = true)\n",
      " |-- v12_01: integer (nullable = true)\n",
      " |-- v12_02: integer (nullable = true)\n",
      " |-- v12_03: integer (nullable = true)\n",
      " |-- v12_04: integer (nullable = true)\n",
      " |-- v12_05: integer (nullable = true)\n",
      " |-- v12_06: integer (nullable = true)\n",
      " |-- v12_07: integer (nullable = true)\n",
      " |-- v12_08: integer (nullable = true)\n",
      " |-- v12_09: integer (nullable = true)\n",
      " |-- v13: integer (nullable = true)\n",
      " |-- v13_01: integer (nullable = true)\n",
      " |-- v13_02: integer (nullable = true)\n",
      " |-- v13_03: integer (nullable = true)\n",
      " |-- v13_04: integer (nullable = true)\n",
      " |-- v13_05: integer (nullable = true)\n",
      " |-- v13_06: integer (nullable = true)\n",
      " |-- v13_07: integer (nullable = true)\n",
      " |-- v13_08: integer (nullable = true)\n",
      " |-- v14: integer (nullable = true)\n",
      " |-- v14_01: integer (nullable = true)\n",
      " |-- v14_02: integer (nullable = true)\n",
      " |-- v14_03: integer (nullable = true)\n",
      " |-- v14_04: integer (nullable = true)\n",
      " |-- v14_05: integer (nullable = true)\n",
      " |-- v14_06: integer (nullable = true)\n",
      " |-- v14_07: integer (nullable = true)\n",
      " |-- v14_08: integer (nullable = true)\n",
      " |-- v14_09: integer (nullable = true)\n",
      " |-- v14_10: integer (nullable = true)\n",
      " |-- v15: integer (nullable = true)\n",
      " |-- v16: integer (nullable = true)\n",
      " |-- v16_01: integer (nullable = true)\n",
      " |-- v16_02: integer (nullable = true)\n",
      " |-- v16_03: integer (nullable = true)\n",
      " |-- v16_04: integer (nullable = true)\n",
      " |-- v16_05: integer (nullable = true)\n",
      " |-- v16_06: integer (nullable = true)\n",
      " |-- v16_07: integer (nullable = true)\n",
      " |-- v16_08: integer (nullable = true)\n",
      " |-- v16_09: integer (nullable = true)\n",
      " |-- v16_10: integer (nullable = true)\n",
      " |-- v16_11: integer (nullable = true)\n",
      " |-- v17: integer (nullable = true)\n",
      " |-- v17_01: integer (nullable = true)\n",
      " |-- v17_02: integer (nullable = true)\n",
      " |-- v17_03: integer (nullable = true)\n",
      " |-- v17_04: integer (nullable = true)\n",
      " |-- v17_05: integer (nullable = true)\n",
      " |-- v17_06: integer (nullable = true)\n",
      " |-- v17_07: integer (nullable = true)\n",
      " |-- v17_08: integer (nullable = true)\n",
      " |-- v18: integer (nullable = true)\n",
      " |-- v18_01: integer (nullable = true)\n",
      " |-- v18_02: integer (nullable = true)\n",
      " |-- v18_03: integer (nullable = true)\n",
      " |-- v18_04: integer (nullable = true)\n",
      " |-- v18_05: integer (nullable = true)\n",
      " |-- v18_06: integer (nullable = true)\n",
      " |-- v18_07: integer (nullable = true)\n",
      " |-- v18_08: integer (nullable = true)\n",
      " |-- v18_09: integer (nullable = true)\n",
      " |-- v18_10: integer (nullable = true)\n",
      " |-- v18_11: integer (nullable = true)\n",
      " |-- v18_12: integer (nullable = true)\n",
      " |-- v18_13: integer (nullable = true)\n",
      " |-- v18_14: integer (nullable = true)\n",
      " |-- v18_15: integer (nullable = true)\n",
      " |-- v18_16: integer (nullable = true)\n",
      " |-- v18_17: integer (nullable = true)\n",
      " |-- v18_18: integer (nullable = true)\n",
      " |-- _expand: integer (nullable = true)\n",
      " |-- ipcm_t0: string (nullable = true)\n",
      " |-- ipcm_pl_t0: double (nullable = true)\n",
      " |-- ipcmr_t0: double (nullable = true)\n",
      " |-- ipcmr_pl_t0: double (nullable = true)\n",
      " |-- gpcm_t0: double (nullable = true)\n",
      " |-- gpcm_pl_t0: double (nullable = true)\n",
      " |-- gpcmr_t0: double (nullable = true)\n",
      " |-- gpcmr_pl_t0: double (nullable = true)\n",
      " |-- pobre_ing_t0: integer (nullable = true)\n",
      " |-- pobre_gas_t0: integer (nullable = true)\n",
      " |-- ipcm_t1: double (nullable = true)\n",
      " |-- ipcm_pl_t1: double (nullable = true)\n",
      " |-- ipcmr_t1: double (nullable = true)\n",
      " |-- ipcmr_pl_t1: double (nullable = true)\n",
      " |-- gpcm_t1: double (nullable = true)\n",
      " |-- gpcm_pl_t1: double (nullable = true)\n",
      " |-- gpcmr_t1: double (nullable = true)\n",
      " |-- gpcmr_pl_t1: double (nullable = true)\n",
      " |-- pobre_ing_t1: integer (nullable = true)\n",
      " |-- pobre_gas_t1: integer (nullable = true)\n",
      " |-- transicion_gas: string (nullable = true)\n",
      " |-- np_p_gas: integer (nullable = true)\n",
      " |-- p_p_gas: integer (nullable = true)\n",
      " |-- np_np_gas: integer (nullable = true)\n",
      " |-- p_np_gas: integer (nullable = true)\n",
      " |-- transicion_ing: string (nullable = true)\n",
      " |-- np_p_ing: integer (nullable = true)\n",
      " |-- p_p_ing: integer (nullable = true)\n",
      " |-- np_np_ing: integer (nullable = true)\n",
      " |-- p_np_ing: integer (nullable = true)\n",
      " |-- regiones: integer (nullable = true)\n",
      " |-- dominio_t0_1: integer (nullable = true)\n",
      " |-- dominio_t0_2: integer (nullable = true)\n",
      " |-- dominio_t0_3: integer (nullable = true)\n",
      " |-- dominio_t0_4: integer (nullable = true)\n",
      " |-- dominio_t0_5: integer (nullable = true)\n",
      " |-- dominio_t0_6: integer (nullable = true)\n",
      " |-- dominio_t0_7: integer (nullable = true)\n",
      " |-- dominio_t0_8: integer (nullable = true)\n",
      " |-- estrategia_1: integer (nullable = true)\n",
      " |-- estrategia_2: integer (nullable = true)\n",
      " |-- estrategia_3: integer (nullable = true)\n",
      " |-- estrategia_4: integer (nullable = true)\n",
      " |-- estrategia_5: integer (nullable = true)\n",
      " |-- vtenencia_1: integer (nullable = true)\n",
      " |-- vtenencia_2: integer (nullable = true)\n",
      " |-- vtenencia_3: integer (nullable = true)\n",
      " |-- educa_1: integer (nullable = true)\n",
      " |-- educa_2: integer (nullable = true)\n",
      " |-- educa_3: integer (nullable = true)\n",
      " |-- educa_4: integer (nullable = true)\n",
      " |-- sector_1: integer (nullable = true)\n",
      " |-- sector_2: integer (nullable = true)\n",
      " |-- sector_3: integer (nullable = true)\n",
      " |-- sector_4: integer (nullable = true)\n",
      " |-- estratosocio_1: integer (nullable = true)\n",
      " |-- estratosocio_2: integer (nullable = true)\n",
      " |-- estratosocio_3: integer (nullable = true)\n",
      " |-- estratosocio_4: integer (nullable = true)\n",
      " |-- estratosocio_5: integer (nullable = true)\n",
      " |-- estratosocio_6: integer (nullable = true)\n",
      " |-- y: integer (nullable = true)\n",
      " |-- edad_mean_cuadrado: double (nullable = true)\n",
      " |-- hactivos_cuadrado: integer (nullable = true)\n",
      " |-- hauto_cuadrado: integer (nullable = true)\n",
      " |-- hcocina_cuadrado: integer (nullable = true)\n",
      " |-- hdvd_cuadrado: integer (nullable = true)\n",
      " |-- heqsonido_cuadrado: integer (nullable = true)\n",
      " |-- hombres_cuadrado: integer (nullable = true)\n",
      " |-- hradio_cuadrado: integer (nullable = true)\n",
      " |-- hrefri_cuadrado: integer (nullable = true)\n",
      " |-- htelef_cuadrado: integer (nullable = true)\n",
      " |-- htv_cuadrado: integer (nullable = true)\n",
      " |-- mieperho_cuadrado: integer (nullable = true)\n",
      " |-- num_accid_cuadrado: integer (nullable = true)\n",
      " |-- num_choq_cuadrado: integer (nullable = true)\n",
      " |-- num_hosp_cuadrado: integer (nullable = true)\n",
      " |-- ratio_educ_cuadrado: double (nullable = true)\n",
      " |-- ratiodep_cuadrado: double (nullable = true)\n",
      " |-- vacceso_cuadrado: integer (nullable = true)\n",
      " |-- yyeduc_cuadrado: integer (nullable = true)\n",
      " |-- sample: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Total Columns: %d' % len(panel_data.dtypes))\n",
    "print('Total Rows: %d' % panel_data.count())\n",
    "panel_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 272\n",
      "Total Rows: 372740\n",
      "root\n",
      " |-- hog_monopa: integer (nullable = true)\n",
      " |-- dominio_t0: string (nullable = true)\n",
      " |-- monop_homb: integer (nullable = true)\n",
      " |-- hacinamien: integer (nullable = true)\n",
      " |-- hog_nucl: integer (nullable = true)\n",
      " |-- monop_muj: integer (nullable = true)\n",
      " |-- a_o: integer (nullable = true)\n",
      " |-- ubigeo_t0: integer (nullable = true)\n",
      " |-- area: integer (nullable = true)\n",
      " |-- vtenencia: string (nullable = true)\n",
      " |-- vagua: integer (nullable = true)\n",
      " |-- vsshh: integer (nullable = true)\n",
      " |-- valum: integer (nullable = true)\n",
      " |-- vacceso: integer (nullable = true)\n",
      " |-- hinternet: integer (nullable = true)\n",
      " |-- htelef: integer (nullable = true)\n",
      " |-- gedad_1: integer (nullable = true)\n",
      " |-- gedad_2: integer (nullable = true)\n",
      " |-- gedad_3: integer (nullable = true)\n",
      " |-- genero: integer (nullable = true)\n",
      " |-- ratiodep: double (nullable = true)\n",
      " |-- edad_mean: double (nullable = true)\n",
      " |-- hombres: integer (nullable = true)\n",
      " |-- conyuge: integer (nullable = true)\n",
      " |-- hpob65: integer (nullable = true)\n",
      " |-- hunip65: integer (nullable = true)\n",
      " |-- hriesgo: integer (nullable = true)\n",
      " |-- h65menor17: integer (nullable = true)\n",
      " |-- gas_svstot: integer (nullable = true)\n",
      " |-- gas_svsal: integer (nullable = true)\n",
      " |-- choque_s5: integer (nullable = true)\n",
      " |-- dep_1: integer (nullable = true)\n",
      " |-- dep_2: integer (nullable = true)\n",
      " |-- dep_3: integer (nullable = true)\n",
      " |-- dep_4: integer (nullable = true)\n",
      " |-- dep_5: integer (nullable = true)\n",
      " |-- dep_6: integer (nullable = true)\n",
      " |-- dep_7: integer (nullable = true)\n",
      " |-- dep_8: integer (nullable = true)\n",
      " |-- dep_9: integer (nullable = true)\n",
      " |-- dep_10: integer (nullable = true)\n",
      " |-- dep_11: integer (nullable = true)\n",
      " |-- dep_12: integer (nullable = true)\n",
      " |-- dep_13: integer (nullable = true)\n",
      " |-- dep_14: integer (nullable = true)\n",
      " |-- dep_16: integer (nullable = true)\n",
      " |-- dep_17: integer (nullable = true)\n",
      " |-- dep_18: integer (nullable = true)\n",
      " |-- dep_19: integer (nullable = true)\n",
      " |-- dep_20: integer (nullable = true)\n",
      " |-- dep_21: integer (nullable = true)\n",
      " |-- dep_22: integer (nullable = true)\n",
      " |-- dep_23: integer (nullable = true)\n",
      " |-- dep_24: integer (nullable = true)\n",
      " |-- dep_25: integer (nullable = true)\n",
      " |-- dep_26: integer (nullable = true)\n",
      " |-- dep_27: integer (nullable = true)\n",
      " |-- dominio_t0_1: integer (nullable = true)\n",
      " |-- dominio_t0_2: integer (nullable = true)\n",
      " |-- dominio_t0_3: integer (nullable = true)\n",
      " |-- dominio_t0_4: integer (nullable = true)\n",
      " |-- dominio_t0_5: integer (nullable = true)\n",
      " |-- dominio_t0_6: integer (nullable = true)\n",
      " |-- dominio_t0_7: integer (nullable = true)\n",
      " |-- dominio_t0_8: integer (nullable = true)\n",
      " |-- vtenencia_1: integer (nullable = true)\n",
      " |-- vtenencia_2: integer (nullable = true)\n",
      " |-- vtenencia_3: integer (nullable = true)\n",
      " |-- mis_gob: integer (nullable = true)\n",
      " |-- ing_inest_1: integer (nullable = true)\n",
      " |-- ing_inest_2: integer (nullable = true)\n",
      " |-- ing_inest_3: integer (nullable = true)\n",
      " |-- choq_emple: integer (nullable = true)\n",
      " |-- choq_quiebr: integer (nullable = true)\n",
      " |-- choq_robo: integer (nullable = true)\n",
      " |-- choq_desast: integer (nullable = true)\n",
      " |-- choq_otros: integer (nullable = true)\n",
      " |-- num_choq: integer (nullable = true)\n",
      " |-- choq_combi: integer (nullable = true)\n",
      " |-- estrategia: string (nullable = true)\n",
      " |-- si_soldism_ibp: integer (nullable = true)\n",
      " |-- no_soldism_ibp: integer (nullable = true)\n",
      " |-- no_asocia: integer (nullable = true)\n",
      " |-- num_accid: integer (nullable = true)\n",
      " |-- seg_nocuen: integer (nullable = true)\n",
      " |-- seg_essal: integer (nullable = true)\n",
      " |-- vpared: integer (nullable = true)\n",
      " |-- vpiso: integer (nullable = true)\n",
      " |-- hauto: integer (nullable = true)\n",
      " |-- hrefri: integer (nullable = true)\n",
      " |-- htv: integer (nullable = true)\n",
      " |-- hdvd: integer (nullable = true)\n",
      " |-- heqsonido: integer (nullable = true)\n",
      " |-- hradio: integer (nullable = true)\n",
      " |-- hcocina: integer (nullable = true)\n",
      " |-- hactivos: integer (nullable = true)\n",
      " |-- indigena: integer (nullable = true)\n",
      " |-- educa: string (nullable = true)\n",
      " |-- seg_sis: integer (nullable = true)\n",
      " |-- seg_otro: integer (nullable = true)\n",
      " |-- sector: string (nullable = true)\n",
      " |-- yyeduc: integer (nullable = true)\n",
      " |-- yyeduc2: integer (nullable = true)\n",
      " |-- ratio_educ: double (nullable = true)\n",
      " |-- num_hosp: integer (nullable = true)\n",
      " |-- hindemp5: integer (nullable = true)\n",
      " |-- htrabemp10: integer (nullable = true)\n",
      " |-- hocu1417: integer (nullable = true)\n",
      " |-- choque_s1: integer (nullable = true)\n",
      " |-- choque_s2: integer (nullable = true)\n",
      " |-- choque_s3: integer (nullable = true)\n",
      " |-- choque_s4: integer (nullable = true)\n",
      " |-- piso_alt_1: integer (nullable = true)\n",
      " |-- piso_alt_2: integer (nullable = true)\n",
      " |-- piso_alt_3: integer (nullable = true)\n",
      " |-- piso_alt_4: integer (nullable = true)\n",
      " |-- piso_alt_5: integer (nullable = true)\n",
      " |-- piso_alt_6: integer (nullable = true)\n",
      " |-- piso_alt_7: integer (nullable = true)\n",
      " |-- piso_alt_8: integer (nullable = true)\n",
      " |-- mieperho: integer (nullable = true)\n",
      " |-- end_lacexc: double (nullable = true)\n",
      " |-- end_anemia: double (nullable = true)\n",
      " |-- end_ira: double (nullable = true)\n",
      " |-- end_eda: double (nullable = true)\n",
      " |-- end_bajpeso: double (nullable = true)\n",
      " |-- end_cred: double (nullable = true)\n",
      " |-- end_suphierro: double (nullable = true)\n",
      " |-- end_aguatrat: double (nullable = true)\n",
      " |-- end_saneabas: double (nullable = true)\n",
      " |-- end_gestsuphie: double (nullable = true)\n",
      " |-- end_usometpf: double (nullable = true)\n",
      " |-- end_partinst: double (nullable = true)\n",
      " |-- end_cesarea: double (nullable = true)\n",
      " |-- end_prematuro: double (nullable = true)\n",
      " |-- end_primercpn: double (nullable = true)\n",
      " |-- end_cpn6: double (nullable = true)\n",
      " |-- mun_dis: integer (nullable = true)\n",
      " |-- v10: integer (nullable = true)\n",
      " |-- v10_01: integer (nullable = true)\n",
      " |-- v10_02: integer (nullable = true)\n",
      " |-- v10_03: integer (nullable = true)\n",
      " |-- v10_04: integer (nullable = true)\n",
      " |-- v10_05: integer (nullable = true)\n",
      " |-- v10_06: integer (nullable = true)\n",
      " |-- v10_07: integer (nullable = true)\n",
      " |-- v11: integer (nullable = true)\n",
      " |-- v11_1: integer (nullable = true)\n",
      " |-- v11_2: integer (nullable = true)\n",
      " |-- v11_3: integer (nullable = true)\n",
      " |-- v11_4: integer (nullable = true)\n",
      " |-- v11_5: integer (nullable = true)\n",
      " |-- v11_6: integer (nullable = true)\n",
      " |-- v11_7: integer (nullable = true)\n",
      " |-- v11_8: integer (nullable = true)\n",
      " |-- v11_9: integer (nullable = true)\n",
      " |-- v11_10: integer (nullable = true)\n",
      " |-- v12: integer (nullable = true)\n",
      " |-- v12_01: integer (nullable = true)\n",
      " |-- v12_02: integer (nullable = true)\n",
      " |-- v12_03: integer (nullable = true)\n",
      " |-- v12_04: integer (nullable = true)\n",
      " |-- v12_05: integer (nullable = true)\n",
      " |-- v12_06: integer (nullable = true)\n",
      " |-- v12_07: integer (nullable = true)\n",
      " |-- v12_08: integer (nullable = true)\n",
      " |-- v12_09: integer (nullable = true)\n",
      " |-- v13: integer (nullable = true)\n",
      " |-- v13_01: integer (nullable = true)\n",
      " |-- v13_02: integer (nullable = true)\n",
      " |-- v13_03: integer (nullable = true)\n",
      " |-- v13_04: integer (nullable = true)\n",
      " |-- v13_05: integer (nullable = true)\n",
      " |-- v13_06: integer (nullable = true)\n",
      " |-- v13_07: integer (nullable = true)\n",
      " |-- v13_08: integer (nullable = true)\n",
      " |-- v14: integer (nullable = true)\n",
      " |-- v14_01: integer (nullable = true)\n",
      " |-- v14_02: integer (nullable = true)\n",
      " |-- v14_03: integer (nullable = true)\n",
      " |-- v14_04: integer (nullable = true)\n",
      " |-- v14_05: integer (nullable = true)\n",
      " |-- v14_06: integer (nullable = true)\n",
      " |-- v14_07: integer (nullable = true)\n",
      " |-- v14_08: integer (nullable = true)\n",
      " |-- v14_09: integer (nullable = true)\n",
      " |-- v14_10: integer (nullable = true)\n",
      " |-- v15: integer (nullable = true)\n",
      " |-- v16: integer (nullable = true)\n",
      " |-- v16_01: integer (nullable = true)\n",
      " |-- v16_02: integer (nullable = true)\n",
      " |-- v16_03: integer (nullable = true)\n",
      " |-- v16_04: integer (nullable = true)\n",
      " |-- v16_05: integer (nullable = true)\n",
      " |-- v16_06: integer (nullable = true)\n",
      " |-- v16_07: integer (nullable = true)\n",
      " |-- v16_08: integer (nullable = true)\n",
      " |-- v16_09: integer (nullable = true)\n",
      " |-- v16_10: integer (nullable = true)\n",
      " |-- v16_11: integer (nullable = true)\n",
      " |-- v17: integer (nullable = true)\n",
      " |-- v17_01: integer (nullable = true)\n",
      " |-- v17_02: integer (nullable = true)\n",
      " |-- v17_03: integer (nullable = true)\n",
      " |-- v17_04: integer (nullable = true)\n",
      " |-- v17_05: integer (nullable = true)\n",
      " |-- v17_06: integer (nullable = true)\n",
      " |-- v17_07: integer (nullable = true)\n",
      " |-- v17_08: integer (nullable = true)\n",
      " |-- v18: integer (nullable = true)\n",
      " |-- v18_01: integer (nullable = true)\n",
      " |-- v18_02: integer (nullable = true)\n",
      " |-- v18_03: integer (nullable = true)\n",
      " |-- v18_04: integer (nullable = true)\n",
      " |-- v18_05: integer (nullable = true)\n",
      " |-- v18_06: integer (nullable = true)\n",
      " |-- v18_07: integer (nullable = true)\n",
      " |-- v18_08: integer (nullable = true)\n",
      " |-- v18_09: integer (nullable = true)\n",
      " |-- v18_10: integer (nullable = true)\n",
      " |-- v18_11: integer (nullable = true)\n",
      " |-- v18_12: integer (nullable = true)\n",
      " |-- v18_13: integer (nullable = true)\n",
      " |-- v18_14: integer (nullable = true)\n",
      " |-- v18_15: integer (nullable = true)\n",
      " |-- v18_16: integer (nullable = true)\n",
      " |-- v18_17: integer (nullable = true)\n",
      " |-- v18_18: integer (nullable = true)\n",
      " |-- estratosocio: string (nullable = true)\n",
      " |-- regiones: integer (nullable = true)\n",
      " |-- estrategia_1: integer (nullable = true)\n",
      " |-- estrategia_2: integer (nullable = true)\n",
      " |-- estrategia_3: integer (nullable = true)\n",
      " |-- estrategia_4: integer (nullable = true)\n",
      " |-- estrategia_5: integer (nullable = true)\n",
      " |-- educa_1: integer (nullable = true)\n",
      " |-- educa_2: integer (nullable = true)\n",
      " |-- educa_3: integer (nullable = true)\n",
      " |-- educa_4: integer (nullable = true)\n",
      " |-- sector_1: integer (nullable = true)\n",
      " |-- sector_2: integer (nullable = true)\n",
      " |-- sector_3: integer (nullable = true)\n",
      " |-- sector_4: integer (nullable = true)\n",
      " |-- estratosocio_1: integer (nullable = true)\n",
      " |-- estratosocio_2: integer (nullable = true)\n",
      " |-- estratosocio_3: integer (nullable = true)\n",
      " |-- estratosocio_4: integer (nullable = true)\n",
      " |-- estratosocio_5: integer (nullable = true)\n",
      " |-- estratosocio_6: integer (nullable = true)\n",
      " |-- edad_mean_cuadrado: double (nullable = true)\n",
      " |-- hactivos_cuadrado: integer (nullable = true)\n",
      " |-- hauto_cuadrado: integer (nullable = true)\n",
      " |-- hcocina_cuadrado: integer (nullable = true)\n",
      " |-- hdvd_cuadrado: integer (nullable = true)\n",
      " |-- heqsonido_cuadrado: integer (nullable = true)\n",
      " |-- hombres_cuadrado: integer (nullable = true)\n",
      " |-- hradio_cuadrado: integer (nullable = true)\n",
      " |-- hrefri_cuadrado: integer (nullable = true)\n",
      " |-- htelef_cuadrado: integer (nullable = true)\n",
      " |-- htv_cuadrado: integer (nullable = true)\n",
      " |-- mieperho_cuadrado: integer (nullable = true)\n",
      " |-- num_accid_cuadrado: integer (nullable = true)\n",
      " |-- num_choq_cuadrado: integer (nullable = true)\n",
      " |-- num_hosp_cuadrado: integer (nullable = true)\n",
      " |-- ratio_educ_cuadrado: double (nullable = true)\n",
      " |-- ratiodep_cuadrado: double (nullable = true)\n",
      " |-- vacceso_cuadrado: integer (nullable = true)\n",
      " |-- yyeduc_cuadrado: integer (nullable = true)\n",
      " |-- gpcm: double (nullable = true)\n",
      " |-- gpcm_pl: double (nullable = true)\n",
      " |-- gpcmr: double (nullable = true)\n",
      " |-- gpcmr_pl: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Total Columns: %d' % len(cs_data.dtypes))\n",
    "print('Total Rows: %d' % cs_data.count())\n",
    "cs_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This  is the variable we are trying to predict: Fall into poverty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|np_p_gas|count|\n",
      "+--------+-----+\n",
      "|       1| 6861|\n",
      "|       0|63206|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(panel_data.groupBy('np_p_gas').count().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test \n",
    "train, test = panel_data.randomSplit([0.8, 0.2], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, MultilayerPerceptronClassifier, RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np \n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['panel', 'conglome_t0', 'vivienda_t0', 'hogar_t0', 'aband_jefe', 'inghog1d_t0', 'gashog2d_t0', 'linea_t0', \\\n",
    "          'mieperho_t1', 'inghog1d_t1', 'gashog2d_t1', 'linea_t1', 'i00_t0', 'i00_t1', 'ld_t0', 'ld_t1', 'facpanel17', \\\n",
    "          'factorhogar_bi', '_expand', 'ipcm_t0', 'ipcm_pl_t0', 'ipcmr_t0', 'ipcmr_pl_t0', 'gpcm_t0', 'gpcm_pl_t0', \\\n",
    "          'gpcmr_t0', 'gpcmr_pl_t0', 'pobre_ing_t0', 'pobre_gas_t0', 'ipcm_t1', 'ipcm_pl_t1', 'ipcmr_t1', 'ipcmr_pl_t1', \\\n",
    "          'gpcm_t1', 'gpcm_pl_t1', 'gpcmr_t1', 'gpcmr_pl_t1', 'pobre_ing_t1', 'pobre_gas_t1', 'transicion_gas', \\\n",
    "          'np_p_gas', 'p_p_gas', 'np_np_gas', 'p_np_gas', 'transicion_ing', 'np_p_ing', 'p_p_ing', 'np_np_ing', \\\n",
    "           'p_np_ing', 'regiones', 'y', 'sample', 'vtenencia', 'dominio_t0', 'estrategia', 'educa', 'sector', 'estratosocio']\n",
    "\n",
    "nr_features = len([x for x in panel_data.columns if x not in ignore])\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[x for x in panel_data.columns if x not in ignore], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression object and add everything to a pipeline\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='np_p_gas')\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='np_p_gas', seed=1)\n",
    "mlpc = MultilayerPerceptronClassifier(featuresCol='features', labelCol='np_p_gas', seed=1)\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='np_p_gas', seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be tested in Logit:  100\n",
      "Number of models to be tested in GBT:  24\n",
      "Number of models to be tested in MLPC:  126\n",
      "Number of models to be tested in RF:  64\n",
      "TOTAL MODELS 314\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid\n",
    "params_lr = ParamGridBuilder() \n",
    "# Add grid for logistic classification parameters, \n",
    "params_lr = params_lr.addGrid(lr.regParam, np.arange(0, .1, .02)) \\\n",
    "                     .addGrid(lr.elasticNetParam, np.arange(0, .1, .02)) \\\n",
    "                     .addGrid(lr.threshold, [0.5, 0.09]) \\\n",
    "                     .addGrid(lr.maxIter, [100, 200])\n",
    "params_lr = params_lr.build()\n",
    "\n",
    "\n",
    "# Create parameter grid\n",
    "params_gbt = ParamGridBuilder() \n",
    "# Add grid for gbt parameters, \n",
    "params_gbt = (params_gbt.addGrid(gbt.maxDepth, [2, 10, 20, 50]) \\\n",
    "                        .addGrid(gbt.maxBins, [20, 32]) \\\n",
    "                        .addGrid(gbt.maxIter, [10, 100, 200]))\n",
    "params_gbt = params_gbt.build()\n",
    "\n",
    "#maxbins default 32 \n",
    "#minInstancesPerNode=1, minInfoGain=0.0,\n",
    "#maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10,\n",
    "#lossType=\"logistic\", maxIter=20, stepSize=0.1, subsamplingRate=1.0\n",
    "\n",
    "# Create parameter grid\n",
    "params_mlpc = ParamGridBuilder() \n",
    "# Add grid for gbt parameters, \n",
    "params_mlpc = (params_mlpc.addGrid(mlpc.layers, [[nr_features, (nr_features+2)/2, 2],\n",
    "                                                 [nr_features, int(math.sqrt(nr_features*2)), 2], \n",
    "                                                 [nr_features, int(train.count()/(2*(nr_features+2))), 2],\n",
    "                                                 [nr_features, int(train.count()/(4*(nr_features+2))), 2],\n",
    "                                                 [nr_features, int(train.count()/(6*(nr_features+2))), 2],\n",
    "                                                 [nr_features, int(train.count()/(8*(nr_features+2))), 2],\n",
    "                                                 [nr_features, int(train.count()/(10*(nr_features+2))), 2],\n",
    "                                                ]) \\\n",
    "                        .addGrid(mlpc.maxIter, [100, 200, 300]) \\\n",
    "                        .addGrid(mlpc.blockSize, [100, 128, 200]) \\\n",
    "                        .addGrid(mlpc.solver, ['gd', 'l-bfgs']))\n",
    "params_mlpc = params_mlpc.build()\n",
    "\n",
    "#maxiter 100\n",
    "# blocksize 128\n",
    "# hidden neurons tips: \n",
    "## limit to 1 \n",
    "## mean of input+output, formula an geometric avg, an alternative formula  \n",
    "##https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "\n",
    "# Create parameter grid\n",
    "params_rf = ParamGridBuilder() \n",
    "# Add grid for gbt parameters, \n",
    "params_rf = (params_rf.addGrid(rf.maxDepth, [2, 10, 20, 50]) \\\n",
    "                        .addGrid(rf.maxBins, [32]) \\\n",
    "                        .addGrid(rf.numTrees, [20, 100, 200, 500]) \\\n",
    "                        .addGrid(rf.impurity, ['entropy', 'gini'])\n",
    "                        .addGrid(rf.featureSubsetStrategy, ['sqrt', 'log2']))\n",
    "params_rf = params_rf.build()\n",
    "\n",
    "\n",
    "print('Number of models to be tested in Logit: ', len(params_lr))\n",
    "print('Number of models to be tested in GBT: ', len(params_gbt))\n",
    "print('Number of models to be tested in MLPC: ', len(params_mlpc))\n",
    "print('Number of models to be tested in RF: ', len(params_rf))\n",
    "print(\"TOTAL MODELS\", len(params_lr)+len(params_gbt)+len(params_mlpc)+len(params_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to be tested in Logit:  32\n",
      "Number of models to be tested in GBT:  6\n",
      "Number of models to be tested in MLPC:  8\n",
      "Number of models to be tested in RF:  6\n",
      "TOTAL MODELS 52\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid\n",
    "params_lr = ParamGridBuilder() \n",
    "# Add grid for logistic classification parameters, \n",
    "params_lr = params_lr.addGrid(lr.regParam, np.arange(0, .1, .03)) \\\n",
    "                     .addGrid(lr.elasticNetParam, np.arange(0, .1, .03)) \\\n",
    "                     .addGrid(lr.threshold, [0.5, 0.09]) \\\n",
    "                     .addGrid(lr.maxIter, [100])\n",
    "params_lr = params_lr.build()\n",
    "\n",
    "\n",
    "# Create parameter grid\n",
    "params_gbt = ParamGridBuilder() \n",
    "# Add grid for gbt parameters, \n",
    "params_gbt = (params_gbt.addGrid(gbt.maxDepth, [2, 5, 10]) \\\n",
    "                        .addGrid(gbt.maxBins, [32]) \\\n",
    "                        .addGrid(gbt.maxIter, [20, 40]))\n",
    "params_gbt = params_gbt.build()\n",
    "\n",
    "#maxbins default 32 , maxDepth=5,  maxBins=32\n",
    "#minInstancesPerNode=1, minInfoGain=0.0,\n",
    "#maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10,\n",
    "#lossType=\"logistic\", maxIter=20, stepSize=0.1, subsamplingRate=1.0\n",
    "\n",
    "# Create parameter grid\n",
    "params_mlpc = ParamGridBuilder() \n",
    "# Add grid for gbt parameters, \n",
    "params_mlpc = (params_mlpc.addGrid(mlpc.layers, [[nr_features, (nr_features+2)/2, 2],\n",
    "                                                 [nr_features, int(math.sqrt(nr_features*2)), 2], \n",
    "                                                ]) \\\n",
    "                        .addGrid(mlpc.maxIter, [100]) \\\n",
    "                        .addGrid(mlpc.blockSize, [100, 128]) \\\n",
    "                        .addGrid(mlpc.solver, ['gd', 'l-bfgs']))\n",
    "params_mlpc = params_mlpc.build()\n",
    "\n",
    "#maxiter 100\n",
    "# blocksize 128\n",
    "# hidden neurons tips: \n",
    "## limit to 1 \n",
    "## mean of input+output, formula an geometric avg, an alternative formula  \n",
    "##https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "\n",
    "# Create parameter grid\n",
    "params_rf = ParamGridBuilder() \n",
    "# Add grid for gbt parameters, \n",
    "params_rf = (params_rf.addGrid(rf.maxDepth, [2, 5]) \\\n",
    "                        .addGrid(rf.maxBins, [32]) \\\n",
    "                        .addGrid(rf.numTrees, [3, 20, 50]) \\\n",
    "                        .addGrid(rf.impurity, ['entropy'])\n",
    "                        .addGrid(rf.featureSubsetStrategy, ['log2']))\n",
    "params_rf = params_rf.build()\n",
    "\n",
    "\n",
    "print('Number of models to be tested in Logit: ', len(params_lr))\n",
    "print('Number of models to be tested in GBT: ', len(params_gbt))\n",
    "print('Number of models to be tested in MLPC: ', len(params_mlpc))\n",
    "print('Number of models to be tested in RF: ', len(params_rf))\n",
    "print(\"TOTAL MODELS\", len(params_lr)+len(params_gbt)+len(params_mlpc)+len(params_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[assembler, lr])\n",
    "pipeline_gbt = Pipeline(stages=[assembler, gbt])\n",
    "pipeline_mlpc = Pipeline(stages=[assembler, mlpc])\n",
    "pipeline_rf = Pipeline(stages=[assembler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "#PR as evaluator\n",
    "# The Precision-Recall Plot Is More Informative than the ROC\n",
    "# When Evaluating Binary Classifiers on Imbalanced Datasets, 2015.\n",
    "# https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432\n",
    "evaluator = BinaryClassificationEvaluator(metricName='areaUnderPR', labelCol='np_p_gas')\n",
    "\n",
    "# Create cross-validator Logit \n",
    "cv_lr = CrossValidator(estimator=pipeline_lr, \n",
    "\t\t\t\t\testimatorParamMaps=params_lr, \n",
    "\t\t\t\t\tevaluator=evaluator, \n",
    "\t\t\t\t\tnumFolds=5)\n",
    "\n",
    "# Create cross-validator GBT\n",
    "cv_gbt = CrossValidator(estimator=pipeline_gbt, \n",
    "\t\t\t\t\testimatorParamMaps=params_gbt, \n",
    "\t\t\t\t\tevaluator=evaluator, \n",
    "\t\t\t\t\tnumFolds=5)\n",
    "\n",
    "# Create cross-validator MLPC\n",
    "cv_mlpc = CrossValidator(estimator=pipeline_mlpc, \n",
    "\t\t\t\t\testimatorParamMaps=params_mlpc, \n",
    "\t\t\t\t\tevaluator=evaluator, \n",
    "\t\t\t\t\tnumFolds=5)\n",
    "\n",
    "# Create cross-validator RF\n",
    "cv_rf = CrossValidator(estimator=pipeline_rf, \n",
    "\t\t\t\t\testimatorParamMaps=params_rf, \n",
    "\t\t\t\t\tevaluator=evaluator, \n",
    "\t\t\t\t\tnumFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit in train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model on multiple folds of the training data\n",
    "## Logit\n",
    "cv_lr = cv_lr.fit(train)\n",
    "\n",
    "## GBT\n",
    "cv_gbt = cv_gbt.fit(train)\n",
    "\n",
    "## MLPC\n",
    "cv_mlpc = cv_mlpc.fit(train)\n",
    "\n",
    "## RF\n",
    "cv_rf = cv_rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************** \n",
      "Logit\n",
      " ****************************************************************************************************\n",
      "[(Param(parent='LogisticRegression_e69ee95bd0e4', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'), 2), (Param(parent='LogisticRegression_e69ee95bd0e4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'), 0.06), (Param(parent='LogisticRegression_e69ee95bd0e4', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'), 'auto'), (Param(parent='LogisticRegression_e69ee95bd0e4', name='featuresCol', doc='features column name.'), 'features'), (Param(parent='LogisticRegression_e69ee95bd0e4', name='fitIntercept', doc='whether to fit an intercept term.'), True), (Param(parent='LogisticRegression_e69ee95bd0e4', name='labelCol', doc='label column name.'), 'np_p_gas'), (Param(parent='LogisticRegression_e69ee95bd0e4', name='maxIter', doc='max number of iterations (>= 0).'), 100), (Param(parent='LogisticRegression_e69ee95bd0e4', name='predictionCol', doc='prediction column name.'), 'prediction'), (Param(parent='LogisticRegression_e69ee95bd0e4', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'), 'probability'), (Param(parent='LogisticRegression_e69ee95bd0e4', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'), 'rawPrediction'), (Param(parent='LogisticRegression_e69ee95bd0e4', name='regParam', doc='regularization parameter (>= 0).'), 0.0), (Param(parent='LogisticRegression_e69ee95bd0e4', name='standardization', doc='whether to standardize the training features before fitting the model.'), True), (Param(parent='LogisticRegression_e69ee95bd0e4', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'), 0.09), (Param(parent='LogisticRegression_e69ee95bd0e4', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'), 1e-06)] \n",
      "\n",
      "**************************************************************************************************** \n",
      "GBT\n",
      " ****************************************************************************************************\n",
      "[(Param(parent='GBTClassifier_72e416a47e4a', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'), False), (Param(parent='GBTClassifier_72e416a47e4a', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'), 10), (Param(parent='GBTClassifier_72e416a47e4a', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"), 'all'), (Param(parent='GBTClassifier_72e416a47e4a', name='featuresCol', doc='features column name.'), 'features'), (Param(parent='GBTClassifier_72e416a47e4a', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'), 'variance'), (Param(parent='GBTClassifier_72e416a47e4a', name='labelCol', doc='label column name.'), 'np_p_gas'), (Param(parent='GBTClassifier_72e416a47e4a', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'), ''), (Param(parent='GBTClassifier_72e416a47e4a', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic'), 'logistic'), (Param(parent='GBTClassifier_72e416a47e4a', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'), 32), (Param(parent='GBTClassifier_72e416a47e4a', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), 5), (Param(parent='GBTClassifier_72e416a47e4a', name='maxIter', doc='max number of iterations (>= 0).'), 40), (Param(parent='GBTClassifier_72e416a47e4a', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'), 256), (Param(parent='GBTClassifier_72e416a47e4a', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'), 0.0), (Param(parent='GBTClassifier_72e416a47e4a', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'), 1), (Param(parent='GBTClassifier_72e416a47e4a', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'), 0.0), (Param(parent='GBTClassifier_72e416a47e4a', name='predictionCol', doc='prediction column name.'), 'prediction'), (Param(parent='GBTClassifier_72e416a47e4a', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'), 'probability'), (Param(parent='GBTClassifier_72e416a47e4a', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'), 'rawPrediction'), (Param(parent='GBTClassifier_72e416a47e4a', name='seed', doc='random seed.'), 1), (Param(parent='GBTClassifier_72e416a47e4a', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'), 0.1), (Param(parent='GBTClassifier_72e416a47e4a', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'), 1.0), (Param(parent='GBTClassifier_72e416a47e4a', name='validationTol', doc='Threshold for stopping early when fit with validation is used. If the error rate on the validation input changes by less than the validationTol, then learning will stop early (before `maxIter`). This parameter is ignored when fit without validation is used.'), 0.01)] \n",
      "\n",
      "**************************************************************************************************** \n",
      "MLPC\n",
      " ****************************************************************************************************\n",
      "[(Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='blockSize', doc='block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data.'), 100), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='featuresCol', doc='features column name.'), 'features'), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='labelCol', doc='label column name.'), 'np_p_gas'), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='maxIter', doc='max number of iterations (>= 0).'), 100), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='predictionCol', doc='prediction column name.'), 'prediction'), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'), 'probability'), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'), 'rawPrediction'), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='seed', doc='random seed.'), 1), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='solver', doc='The solver algorithm for optimization. Supported options: l-bfgs, gd.'), 'l-bfgs'), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='stepSize', doc='Step size to be used for each iteration of optimization (>= 0).'), 0.03), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'), 1e-06), (Param(parent='MultilayerPerceptronClassifier_18d98cadd821', name='layers', doc='Sizes of layers from input layer to output layer E.g., Array(780, 100, 10) means 780 inputs, one hidden layer with 100 neurons and output layer of 10 neurons.'), [260, 22, 2])] \n",
      "\n",
      "**************************************************************************************************** \n",
      "RF\n",
      " ****************************************************************************************************\n",
      "[(Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='bootstrap', doc='Whether bootstrap samples are used when building trees.'), True), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'), False), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'), 10), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"), 'log2'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='featuresCol', doc='features column name.'), 'features'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'), 'entropy'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='labelCol', doc='label column name.'), 'np_p_gas'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'), ''), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'), 32), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'), 5), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'), 256), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'), 0.0), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'), 1), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'), 0.0), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='numTrees', doc='Number of trees to train (>= 1).'), 50), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='predictionCol', doc='prediction column name.'), 'prediction'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'), 'probability'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'), 'rawPrediction'), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='seed', doc='random seed.'), 1), (Param(parent='RandomForestClassifier_0f5c3a2ec4e5', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'), 1.0)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from cross validation\n",
    "best_model_lr = cv_lr.bestModel\n",
    "best_model_gbt = cv_gbt.bestModel\n",
    "best_model_mlpc = cv_mlpc.bestModel\n",
    "best_model_rf = cv_rf.bestModel\n",
    "\n",
    "# What's the optimal parameter value?\n",
    "print(\"*\"*100, \"\\nLogit\\n\", \"*\"*100)\n",
    "print(list(best_model_lr.stages[-1].extractParamMap().items()), \"\\n\")\n",
    "print(\"*\"*100, \"\\nGBT\\n\", \"*\"*100)\n",
    "print(list(best_model_gbt.stages[-1].extractParamMap().items()), \"\\n\")\n",
    "print(\"*\"*100, \"\\nMLPC\\n\", \"*\"*100)\n",
    "print(list(best_model_mlpc.stages[-1].extractParamMap().items()), \"\\n\")\n",
    "print(\"*\"*100, \"\\nRF\\n\", \"*\"*100)\n",
    "print(list(best_model_rf.stages[-1].extractParamMap().items()), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions in test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = best_model_lr.transform(test)\n",
    "predictions_gbt = best_model_gbt.transform(test)\n",
    "predictions_mlpc = best_model_mlpc.transform(test)\n",
    "predictions_rf = best_model_rf.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "threshold = 0.09\n",
    "\n",
    "def print_metrics(predictions, vul_thresh = True, thresh = threshold):\n",
    "    \n",
    "    # Calculate the elements of the confusion matrix\n",
    "    if vul_thresh:\n",
    "        # my prediction uses a specific prob. threshold of 9% from transition matrices  \n",
    "        ## parse values from vector \n",
    "        predictions = (predictions\n",
    "                       .withColumn(\"prob_hat\", vector_to_array(\"probability\"))) \\\n",
    "        .select([\"panel\", 'conglome_t0', 'vivienda_t0', 'hogar_t0', 'np_p_gas', 'rawPrediction', 'prediction'] \n",
    "        + [col(\"prob_hat\")[i] for i in range(2)])\n",
    "        \n",
    "        ## rename, use threshold and convert to integer \n",
    "        predictions = predictions.withColumnRenamed(\"prob_hat[1]\", \"prob_hat1\")\n",
    "        predictions = predictions.withColumn(\"pred_hat_bool\", predictions.prob_hat1 > thresh)\n",
    "        predictions = predictions.withColumn(\"pred_hat\", predictions.pred_hat_bool.cast(\"integer\"))\n",
    "        \n",
    "        TN = predictions.filter('pred_hat = 0 AND np_p_gas = pred_hat').count()\n",
    "        TP = predictions.filter('pred_hat = 1 AND np_p_gas = pred_hat').count()\n",
    "        FN = predictions.filter('pred_hat = 0 AND np_p_gas != pred_hat').count()\n",
    "        FP = predictions.filter('pred_hat = 1 AND np_p_gas != pred_hat').count()\n",
    "    \n",
    "    else:\n",
    "        TN = predictions.filter('prediction = 0 AND np_p_gas = prediction').count()\n",
    "        TP = predictions.filter('prediction = 1 AND np_p_gas = prediction').count()\n",
    "        FN = predictions.filter('prediction = 0 AND np_p_gas != prediction').count()\n",
    "        FP = predictions.filter('prediction = 1 AND np_p_gas != prediction').count()\n",
    "        \n",
    "    # Accuracy measures the proportion of correct predictions\n",
    "    accuracy = (TN + TP) / (TN + TP + FN + FP) \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    \n",
    "   #predictions = best_model.transform(test)\n",
    "    \n",
    "    print(\"areaUnderPR:\", BinaryClassificationEvaluator(metricName='areaUnderPR', labelCol='np_p_gas')\n",
    "      .evaluate(predictions))\n",
    "    print(\"areaUnderROC:\", BinaryClassificationEvaluator(metricName='areaUnderROC', labelCol='np_p_gas')\n",
    "      .evaluate(predictions))\n",
    "    print('Accuracy (not good imbalanced data):', accuracy)\n",
    "    print('Balanced accuracy:', (recall + TNR)/2)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall / TPR:', recall)\n",
    "    print('True Negative Rate:', TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* \n",
      "Logit\n",
      "*******\n",
      "areaUnderPR: 0.3338553934682698\n",
      "areaUnderROC: 0.8292274056181448\n",
      "Accuracy (not good imbalanced data): 0.7196775114155252\n",
      "Balanced accuracy: 0.7504219611504015\n",
      "Precision: 0.23128964059196616\n",
      "Recall / TPR: 0.7887527036770007\n",
      "True Negative Rate: 0.7120912186238023\n",
      "\n",
      "******* \n",
      "GBT\n",
      "*******\n",
      "areaUnderPR: 0.3239686476041005\n",
      "areaUnderROC: 0.8156813751300707\n",
      "Accuracy (not good imbalanced data): 0.6842180365296804\n",
      "Balanced accuracy: 0.7342749144617027\n",
      "Precision: 0.2105162888169175\n",
      "Recall / TPR: 0.7966834895457823\n",
      "True Negative Rate: 0.671866339377623\n",
      "\n",
      "******* \n",
      "MLPC\n",
      "*******\n",
      "areaUnderPR: 0.12201193460768982\n",
      "areaUnderROC: 0.5004930801225798\n",
      "Accuracy (not good imbalanced data): 0.09895833333333333\n",
      "Balanced accuracy: 0.5\n",
      "Precision: 0.09895833333333333\n",
      "Recall / TPR: 1.0\n",
      "True Negative Rate: 0.0\n",
      "\n",
      "******* \n",
      "RF\n",
      "*******\n",
      "areaUnderPR: 0.2647159039978538\n",
      "areaUnderROC: 0.7654683835849363\n",
      "Accuracy (not good imbalanced data): 0.51912100456621\n",
      "Balanced accuracy: 0.6766756546128168\n",
      "Precision: 0.1557556270096463\n",
      "Recall / TPR: 0.8731074260994953\n",
      "True Negative Rate: 0.48024388312613825\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{} \\nLogit\\n{}\".format('*'*7, '*'*7))\n",
    "print_metrics(predictions_lr)\n",
    "print(\"\\n{} \\nGBT\\n{}\".format('*'*7, '*'*7))\n",
    "print_metrics(predictions_gbt) \n",
    "print(\"\\n{} \\nMLPC\\n{}\".format('*'*7, '*'*7))\n",
    "print_metrics(predictions_mlpc) \n",
    "print(\"\\n{} \\nRF\\n{}\".format('*'*7, '*'*7))\n",
    "print_metrics(predictions_rf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prediction out of sample on Cross Section DB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average of household in a 1% caliper from the threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lv(best_model, cs_data=cs_data, caliper=0.01, threshold=0.09, verbose=False):\n",
    "    predictions_cs = best_model.transform(cs_data)\n",
    "    to_avg  = (predictions_cs.withColumn(\"prob_hat\", vector_to_array(\"probability\"))) \\\n",
    "            .select(['a_o', 'gpcmr_pl'] + [col(\"prob_hat\")[i] for i in range(2)])\n",
    "    to_avg = to_avg.withColumnRenamed(\"prob_hat[1]\", \"prob_hat1\")\n",
    "    if verbose: to_avg.show()\n",
    "    \n",
    "    # Filter to a +-1% caliper \n",
    "    to_avg_thresh = to_avg.filter(to_avg.prob_hat1 > (threshold-caliper)) \\\n",
    "                          .filter(to_avg.prob_hat1 < (threshold+caliper))\n",
    "\n",
    "    # Number of households for a more robust mean\n",
    "    print(\"Number of households used in mean:\", to_avg_thresh.count())\n",
    "    \n",
    "    # Obtain the Vulnerability Line in PEN, Lima prices 2018\n",
    "    lv_frame = to_avg_thresh.groupBy().avg('gpcmr_pl')\n",
    "    lv = lv_frame.collect()[0][0]\n",
    "    print(\"Vulnerability line in PEN Lima2018:\", lv)\n",
    "    return lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* \n",
      "Logit\n",
      "*******\n",
      "Number of households used in mean: 16707\n",
      "Vulnerability line in PEN Lima2018: 592.1212685244506\n",
      "\n",
      "******* \n",
      "GBT\n",
      "*******\n",
      "Number of households used in mean: 23723\n",
      "Vulnerability line in PEN Lima2018: 649.1962288671759\n",
      "\n",
      "******* \n",
      "MLPC\n",
      "*******\n",
      "Number of households used in mean: 371783\n",
      "Vulnerability line in PEN Lima2018: 740.625724848278\n",
      "\n",
      "******* \n",
      "RF\n",
      "*******\n",
      "Number of households used in mean: 141655\n",
      "Vulnerability line in PEN Lima2018: 867.4989140534395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "867.4989140534395"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n{} \\nLogit\\n{}\".format('*'*7, '*'*7))\n",
    "compute_lv(best_model_lr, cs_data=cs_data, caliper=0.01, threshold=0.09)\n",
    "print(\"\\n{} \\nGBT\\n{}\".format('*'*7, '*'*7))\n",
    "compute_lv(best_model_gbt, cs_data=cs_data, caliper=0.01, threshold=0.09)\n",
    "print(\"\\n{} \\nMLPC\\n{}\".format('*'*7, '*'*7))\n",
    "compute_lv(best_model_mlpc, cs_data=cs_data, caliper=0.01, threshold=0.09)\n",
    "print(\"\\n{} \\nRF\\n{}\".format('*'*7, '*'*7))\n",
    "compute_lv(best_model_rf, cs_data=cs_data, caliper=0.01, threshold=0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 3400  # milliseconds\n",
    "freq = 250  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of households used in mean: 16707\n",
      "Vulnerability line in PEN Lima2018: 592.1212685244506\n"
     ]
    }
   ],
   "source": [
    "lv = compute_lv(best_model_lr, cs_data=cs_data, caliper=0.01, threshold=0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<font size=5> Conslusion from this script: <p> The Vulnerability Line in PEN, Lima prices 2018 is <b><u>592.1212685244506</b></u>. <p> We now use this value in the Poverty Map using Dask and Pandas (script 3)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given the metrics, lr is chosen \n",
    "md(f\"<font size=5> Conslusion from this script: <p> The Vulnerability Line in PEN, Lima prices 2018 is <b><u>{lv}</b></u>. <p> We now use this value in the Poverty Map using Dask and Pandas (script 3)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
